{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intro():\n",
    "    \"\"\"This function creates a starting message which ilustrates the legend\n",
    "    of further symbols used in the code\"\"\"\n",
    "    print('+---------------------------------+')\n",
    "    print('|  STRING FROM GRAMMAR GENERATOR  |')\n",
    "    print('|          G = (N,Ʃ,P,S)          |')\n",
    "    print('|                                 |')\n",
    "    print('| N - nonterminal symbols         |')\n",
    "    print('| Ʃ - terminal symbols            |')\n",
    "    print('| P - production rules            |')\n",
    "    print('| S - start symbol                |')\n",
    "    print('+---------------------------------+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read():\n",
    "    \"\"\"This function reads all data from the grammer.txt file, which includes\n",
    "    noterminal symbols, terminal symbols, production rules and the string\n",
    "    to analyze\"\"\"\n",
    "    global terminal_symbols\n",
    "    global nonterminal_symbols\n",
    "    global rules\n",
    "    global to_analyze_string\n",
    "    \n",
    "    file = open('grammar.txt', 'r')\n",
    "\n",
    "    line = file.readline()\n",
    "    terminal_symbols = []\n",
    "    while line[:-1] != 'next':\n",
    "        terminal_symbols.append(line[:-1])\n",
    "        line = file.readline()\n",
    "\n",
    "    line = file.readline()\n",
    "    nonterminal_symbols = []\n",
    "    while line[:-1] != 'next':\n",
    "        nonterminal_symbols.append(line[:-1])\n",
    "        line = file.readline()\n",
    "\n",
    "    line = file.readline()\n",
    "    rules = []\n",
    "    while line[:-1] != 'next':\n",
    "        rules.append(line[:-1])\n",
    "        line = file.readline()\n",
    "    \n",
    "    to_analyze_string = file.readline()\n",
    "    to_analyze_string = to_analyze_string[:-1]\n",
    "    \n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_intro_data():\n",
    "    \"\"\"This function print the read data. Usefull function to check\n",
    "    that everything is allright.\"\"\"\n",
    "\n",
    "    global terminal_symbols\n",
    "    global nonterminal_symbols\n",
    "    global rules \n",
    "    global to_analyze_string\n",
    "\n",
    "    print('The grammer is:')\n",
    "    print('G(N,Ʃ,P,S)')\n",
    "\n",
    "    output = 'Ʃ = {'\n",
    "    for x in terminal_symbols:\n",
    "        output += x + ', '\n",
    "    output = output[:(len(output) - 2)]\n",
    "    output += '}'\n",
    "    print(output)\n",
    "\n",
    "    output = 'N = {'\n",
    "    for x in nonterminal_symbols:\n",
    "        output += x + ', '\n",
    "    output = output[:(len(output) - 2)]\n",
    "    output += '}'\n",
    "    print(output)\n",
    "\n",
    "    output = 'P = {\\n'\n",
    "    for x in rules:\n",
    "        output += '\\t' + x + '\\n'\n",
    "    output += '}'\n",
    "    print(output)\n",
    "    \n",
    "    print('String to analyze:', to_analyze_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grammar_to_dictionary():\n",
    "    \"\"\"This function convers string read production rules in dictionary\n",
    "    where the key is the left symbol and on right is a list of symbol from \n",
    "    the right of arrow, For exeample: A -> ab, {'A' : [['a', 'b']]}\"\"\"\n",
    "    \n",
    "    global rules_dic\n",
    "    \n",
    "    rules_dic = {}\n",
    "    for rule in rules:\n",
    "        if not (rule[0] in rules_dic):\n",
    "            rules_dic[rule[0]] = []\n",
    "        start = rule.index('>') + 2\n",
    "        right_production_rule = rule[start:len(rule)]\n",
    "        symbols = []\n",
    "        for symbol in right_production_rule:\n",
    "            symbols.append(symbol)\n",
    "        rules_dic[rule[0]].append(symbols)\n",
    "    print(rules_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_first_last_table():\n",
    "    \"\"\"This function created the the sets FIRST and LAST. Also it prints it.\n",
    "    The data is stored in first-last dictionary\"\"\"\n",
    "    \n",
    "    global rules_dic\n",
    "    global nonterminal_symbols\n",
    "    global first_last\n",
    "    \n",
    "    first_last = {'index' : [], 'FIRST' : [], 'LAST' : []}\n",
    "    index = []\n",
    "    first = []\n",
    "    last = []\n",
    "    for symbol in rules_dic:\n",
    "        index.append(symbol) \n",
    "        to_search = []\n",
    "        to_search.append(symbol)\n",
    "        searched = []\n",
    "        symbol_first = []\n",
    "        symbol_last = []\n",
    "        nr = 0\n",
    "        while nr < len(to_search):\n",
    "            if to_search[nr] in rules_dic:\n",
    "                searched.append(to_search[nr])\n",
    "                for rule in rules_dic[to_search[nr]]:\n",
    "                    if rule[0] not in symbol_first:\n",
    "                        symbol_first.append(rule[0])\n",
    "                    if rule[0] in nonterminal_symbols and rule[0] not in searched:\n",
    "                        to_search.append(rule[0])\n",
    "            nr += 1\n",
    "        first.append(symbol_first)\n",
    "        to_search = []\n",
    "        to_search.append(symbol)\n",
    "        searched = []\n",
    "        nr = 0\n",
    "        while nr < len(to_search):\n",
    "            if to_search[nr] in rules_dic:\n",
    "                searched.append(to_search[nr])\n",
    "                for rule in rules_dic[to_search[nr]]:\n",
    "                    if rule[-1] not in symbol_last:\n",
    "                        symbol_last.append(rule[-1])\n",
    "                    if rule[-1] in nonterminal_symbols and rule[-1] not in searched:\n",
    "                        to_search.append(rule[-1])\n",
    "            nr += 1\n",
    "        last.append(symbol_last)\n",
    "    first_last['index'] = index\n",
    "    first_last['FIRST'] = first\n",
    "    first_last['LAST'] = last\n",
    "    \n",
    "    first_last_table = pd.DataFrame(first_last)\n",
    "    first_last_table.set_index('index')\n",
    "    \n",
    "    #print(first_last)\n",
    "    print(first_last_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_matrix():\n",
    "    \"\"\"This function creates the matrix of simple precedence, using data\n",
    "    made earlier in the code.\"\"\"\n",
    "    global first_last\n",
    "    global nonterminal_symbols\n",
    "    global terminal_symbols\n",
    "    global rules_dic\n",
    "    global matrix\n",
    "    global all_symbols\n",
    "    \n",
    "    # 1. Create 2D matrix\n",
    "    \n",
    "    # a. Construct a dict with symbol and its nr. order \n",
    "    nr = 0\n",
    "    all_symbols = {}\n",
    "    for symbol in nonterminal_symbols:\n",
    "        all_symbols[symbol] = nr\n",
    "        nr += 1\n",
    "    for symbol in terminal_symbols:\n",
    "        all_symbols[symbol] = nr\n",
    "        nr += 1\n",
    "    #print(all_symbols, '\\n')\n",
    "    # b. Create the 2D array\n",
    "    matrix = [[[] for x in range(nr + 1)] for y in range(nr + 1)]\n",
    "    nr = 1\n",
    "    for symbol in nonterminal_symbols:\n",
    "        matrix[0][nr].append(symbol)\n",
    "        matrix[nr][0].append(symbol)\n",
    "        nr += 1\n",
    "    for symbol in terminal_symbols:\n",
    "        matrix[0][nr].append(symbol)\n",
    "        matrix[nr][0].append(symbol)\n",
    "        nr += 1\n",
    "    #First rule : equal sign (=). Navigate in every production rule, 2 by 2 symbols\n",
    "    for symbol in rules_dic:\n",
    "        for rule in rules_dic[symbol]:\n",
    "            if len(rule) > 1:\n",
    "                for index in range(len(rule) - 1):\n",
    "                    symbol_1 = rule[index]\n",
    "                    symbol_2 = rule[index + 1]\n",
    "                    if '=' not in matrix[all_symbols[symbol_1] + 1][all_symbols[symbol_2] + 1]:\n",
    "                        matrix[all_symbols[symbol_1] + 1][all_symbols[symbol_2] + 1].append('=')\n",
    "    \n",
    "    #print(pd.DataFrame(matrix))\n",
    "\n",
    "    #Second rule : smaller sign (<). Navigate in every production rule, 2 by 2\n",
    "    for symbol in rules_dic:\n",
    "        for rule in rules_dic[symbol]:\n",
    "            if len(rule) > 1:\n",
    "                for index in range(len(rule) - 1):\n",
    "                    symbol_1 = rule[index]\n",
    "                    symbol_2 = rule[index + 1]\n",
    "                    if symbol_2 in nonterminal_symbols:\n",
    "                        index_symbol_2 = first_last['index'].index(symbol_2)\n",
    "                        for _symbol in first_last['FIRST'][index_symbol_2]:\n",
    "                            if '<' not in matrix[all_symbols[symbol_1] + 1][all_symbols[_symbol] + 1]:\n",
    "                                matrix[all_symbols[symbol_1] + 1][all_symbols[_symbol] + 1].append('<')\n",
    "    \n",
    "    #print(pd.DataFrame(matrix))\n",
    "\n",
    "    #Third rule : bigger sign (>). Navigate in every production rule, 2 by 2\n",
    "    for symbol in rules_dic:\n",
    "        for rule in rules_dic[symbol]:\n",
    "            if len(rule) > 1:\n",
    "                for index in range(len(rule) - 1):\n",
    "                    symbol_1 = rule[index]\n",
    "                    symbol_2 = rule[index + 1]\n",
    "                    # If symbol_2 is a terminal symbol\n",
    "                    if symbol_2 in terminal_symbols and symbol_1 in nonterminal_symbols:\n",
    "                        index_symbol_1 = first_last['index'].index(symbol_1)\n",
    "                        for _symbol in first_last['LAST'][index_symbol_1]:\n",
    "                            if '>' not in matrix[all_symbols[_symbol] + 1][all_symbols[symbol_2] + 1]:\n",
    "                                matrix[all_symbols[_symbol] + 1][all_symbols[symbol_2] + 1].append('>')\n",
    "                    #If symbol_1 is a nonterminal symbol\n",
    "                    if symbol_2 in nonterminal_symbols and symbol_1 in nonterminal_symbols:\n",
    "                        index_symbol_1 = first_last['index'].index(symbol_1)\n",
    "                        index_symbol_2 = first_last['index'].index(symbol_2)\n",
    "                        for _symbol_1 in first_last['LAST'][index_symbol_1]:\n",
    "                            for _symbol_2 in first_last['FIRST'][index_symbol_2]:\n",
    "                                if _symbol_2 in terminal_symbols:\n",
    "                                    if '>' not in matrix[all_symbols[_symbol_1] + 1][all_symbols[_symbol_2] + 1]:\n",
    "                                        matrix[all_symbols[_symbol_1] + 1][all_symbols[_symbol_2] + 1].append('>')\n",
    "    print(pd.DataFrame(matrix)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_analyses():\n",
    "    \"\"\"This function analyze the string given as input. It prints all\n",
    "    the steps made in the process of analysis.\"\"\"\n",
    "    global to_analyze_string\n",
    "    global matrix\n",
    "    global all_symbols\n",
    "    global rules_dic\n",
    "    \n",
    "    # Create Analyze list\n",
    "    analyze_list = []\n",
    "    analyze_list.append(to_analyze_string[0])\n",
    "    for index in range(1, len(to_analyze_string)):\n",
    "        line_position = all_symbols[to_analyze_string[index - 1]] + 1\n",
    "        column_position = all_symbols[to_analyze_string[index]] + 1\n",
    "        analyze_list.append(matrix[line_position][column_position][0])\n",
    "        analyze_list.append(to_analyze_string[index])\n",
    "\n",
    "    print('Create Analyze list :',''.join(analyze_list))\n",
    "    \n",
    "    while len(analyze_list) != 1 and analyze_list[0] != 'S':\n",
    "        \n",
    "        # Find production rules which matches sublist in Analyze list\n",
    "        start_index = 0\n",
    "        end_index = 1\n",
    "        while 1:\n",
    "            if end_index < len(analyze_list) and analyze_list[end_index] != '<' and analyze_list[end_index] != '>':\n",
    "                end_index += 1\n",
    "            else:\n",
    "                potential_rule = analyze_list[start_index:end_index]\n",
    "                potential_rule = ''.join(potential_rule)\n",
    "                potential_rule = potential_rule.replace('=','')\n",
    "\n",
    "                is_potential_rule_ok = False\n",
    "\n",
    "                for symbol in rules_dic:\n",
    "                    for rule in rules_dic[symbol]:\n",
    "                        existing_rule = ''.join(rule)\n",
    "                        if existing_rule == potential_rule:\n",
    "                            is_potential_rule_ok = True\n",
    "                            to_change_symbol = symbol\n",
    "\n",
    "                if is_potential_rule_ok == True:\n",
    "                    analyze_list[start_index] = to_change_symbol\n",
    "                    if end_index < len(analyze_list):\n",
    "                        analyze_list[end_index] = ' '\n",
    "                    if start_index > 0:\n",
    "                        analyze_list[start_index - 1] = ' '\n",
    "                    del analyze_list[start_index + 1 : end_index]\n",
    "                    break\n",
    "                else:\n",
    "                    start_index = end_index + 1\n",
    "                    end_index += 2\n",
    "        print('Change production rule :',''.join(analyze_list))\n",
    "        \n",
    "        #Update Analyze list '<', '>', '=' symbols\n",
    "        for index in range(len(analyze_list)//2):\n",
    "            line_position = all_symbols[analyze_list[index * 2]] + 1\n",
    "            column_position = all_symbols[analyze_list[index * 2 + 2]] + 1\n",
    "            analyze_list[index * 2 + 1] = matrix[line_position][column_position][0]\n",
    "        print('Update Analyze list :', ''.join(analyze_list))\n",
    "        \n",
    "    if len(analyze_list) == 1 and analyze_list[0] == 'S':\n",
    "        print('Correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|  STRING FROM GRAMMAR GENERATOR  |\n",
      "|          G = (N,Ʃ,P,S)          |\n",
      "|                                 |\n",
      "| N - nonterminal symbols         |\n",
      "| Ʃ - terminal symbols            |\n",
      "| P - production rules            |\n",
      "| S - start symbol                |\n",
      "+---------------------------------+\n",
      "The grammer is:\n",
      "G(N,Ʃ,P,S)\n",
      "Ʃ = {a, b, c, d, e, f}\n",
      "N = {S, A, B, C}\n",
      "P = {\n",
      "\tS -> Bc\n",
      "\tS -> BcdC\n",
      "\tC -> Ae\n",
      "\tA -> f\n",
      "\tA -> Abf\n",
      "\tB -> a\n",
      "\tB -> Bba\n",
      "}\n",
      "String to analyze: abacdfbfe\n",
      "_____________________________________________________________________________\n",
      "Transfering production rules in dictionary. The keys are nonterminal symbols \n",
      "\n",
      "{'S': [['B', 'c'], ['B', 'c', 'd', 'C']], 'C': [['A', 'e']], 'A': [['f'], ['A', 'b', 'f']], 'B': [['a'], ['B', 'b', 'a']]}\n",
      "_____________________________________________________________________________\n",
      "Creating the FIRST-LAST table for Simple Precedence \n",
      "\n",
      "  index   FIRST       LAST\n",
      "0     S  [B, a]  [c, C, e]\n",
      "1     C  [A, f]        [e]\n",
      "2     A  [f, A]        [f]\n",
      "3     B  [a, B]        [a]\n",
      "_____________________________________________________________________________\n",
      "Constructing the matrix of Simple Precedence \n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9    10\n",
      "0    []  [S]  [A]  [B]  [C]  [a]  [b]  [c]  [d]  [e]  [f]\n",
      "1   [S]   []   []   []   []   []   []   []   []   []   []\n",
      "2   [A]   []   []   []   []   []  [=]   []   []  [=]   []\n",
      "3   [B]   []   []   []   []   []  [=]  [=]   []   []   []\n",
      "4   [C]   []   []   []   []   []   []   []   []   []   []\n",
      "5   [a]   []   []   []   []   []  [>]  [>]   []   []   []\n",
      "6   [b]   []   []   []   []  [=]   []   []   []   []  [=]\n",
      "7   [c]   []   []   []   []   []   []   []  [=]   []   []\n",
      "8   [d]   []  [<]   []  [=]   []   []   []   []   []  [<]\n",
      "9   [e]   []   []   []   []   []   []   []   []   []   []\n",
      "10  [f]   []   []   []   []   []  [>]   []   []  [>]   []\n",
      "_____________________________________________________________________________\n",
      "Analyses of  abacdfbfe \n",
      "\n",
      "Create Analyze list : a>b=a>c=d<f>b=f>e\n",
      "Change production rule : B b=a>c=d<f>b=f>e\n",
      "Update Analyze list : B=b=a>c=d<f>b=f>e\n",
      "Change production rule : B c=d<f>b=f>e\n",
      "Update Analyze list : B=c=d<f>b=f>e\n",
      "Change production rule : B=c=d A b=f>e\n",
      "Update Analyze list : B=c=d<A=b=f>e\n",
      "Change production rule : B=c=d A e\n",
      "Update Analyze list : B=c=d<A=e\n",
      "Change production rule : B=c=d C\n",
      "Update Analyze list : B=c=d=C\n",
      "Change production rule : S\n",
      "Update Analyze list : S\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This is the main code which call all the function to do the\n",
    "the relations of simple precedence correctly\"\"\"\n",
    "terminal_symbols = []\n",
    "nonterminal_symbols = []\n",
    "rules = []\n",
    "rules_dic = {}\n",
    "first_last = {}\n",
    "to_analyze_string = ''\n",
    "matrix = []\n",
    "all_symbols = {}\n",
    "\n",
    "intro()\n",
    "read()\n",
    "output_intro_data()\n",
    "print('_____________________________________________________________________________')\n",
    "print('Transfering production rules in dictionary. The keys are nonterminal symbols \\n')\n",
    "grammar_to_dictionary()\n",
    "print('_____________________________________________________________________________')\n",
    "print('Creating the FIRST-LAST table for Simple Precedence \\n')\n",
    "create_first_last_table()\n",
    "print('_____________________________________________________________________________')\n",
    "print('Constructing the matrix of Simple Precedence \\n')\n",
    "construct_matrix()\n",
    "print('_____________________________________________________________________________')\n",
    "print('Analyses of ', to_analyze_string, '\\n')\n",
    "string_analyses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
